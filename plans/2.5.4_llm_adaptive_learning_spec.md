---
task_id: llm-adaptive-learning
type: FEAT
complexity: F
current_phase: P2
completed_phases: [P0, P0.B, P1, P2]
branch: feature/llm-adaptive-learning
audit_iteration: 1
created_at: 2026-01-11
updated_at: 2026-01-11
---

## P2.A 审计报告

**规格书**: plans/2.5.4_llm_adaptive_learning_spec.md
**审计时间**: 2026-01-11
**审计工具**: Gemini 3 Pro

### 审计结果: 有条件通过

### 问题清单

#### 阻塞级 (已修正)

- [x] **B1** 相似度算法方案矛盾：1.3 节选定 "TF-IDF 余弦相似度"，但 2.5 节代码使用 Jaccard
  → 已统一使用 Jaccard 相似度（简单有效，无额外依赖）

- [x] **B2** 并发模型隐患：`async` 函数内直接调用同步 CPU 密集型函数 `extract_mda_iterative`
  → 已添加 `run_in_executor` 包装说明

#### 重要级 (已修正)

- [x] **I1** `FewShotSample` 缺失 `toc_signature` 字段
  → 已补充字段

- [x] **I2** `_parse_json_response` 返回空字典导致静默失败
  → 已改为抛出 `JSONParseError` 并终止当前迭代

- [x] **I3** 规则持久化逻辑模糊
  → 已在 Phase C2 补充详细入库逻辑

#### 优化级 (记录待改进)

- [ ] **O1** 增强 JSON 解析容错（考虑 `json_repair` 库）
- [ ] **O2** 细化 LLM 提供商降级策略（区分 429 和 5xx）

### 历史教训匹配

- 无匹配历史教训

### 结论

所有阻塞级和重要级问题已修正，规格书可进入实现阶段。

---

# Phase 2.5.4: LLM 自适应学习 — 规格书

## 问题定义 (P0)

**类型**: FEAT-F (完整新功能)

**背景**: 通过上下文工程实现等效"学习"能力，无需微调模型。核心架构如下：

```
输入年报 → 检索相似成功案例 → 构建 prompt
    ↓
多策略提取 → LLM-as-Judge 评分
    ↓
评分 ≥ 阈值?
  ├─ 是 → 存入成功样本库 → 输出
  └─ 否 → Self-Refine → 重试(最多N次)
             ↓
        仍失败 → 记录失败模式 → 人工队列
```

**范围**:

**做**:
1. [P2] LLM API 客户端（支持 DeepSeek/Qwen/GPT-4o-mini/Claude 多提供商）
2. [P2] Prompt 模板设计（分析目录结构，提取 start/end pattern）
3. [P2] 规则写入 `extraction_rules` 表的逻辑
4. [P1] Self-Refine 模式（提取 → 自我评估 → 修正重提取）
5. [P2] 动态 Few-shot 样本库（成功案例向量化存储）
6. [P2] 策略权重自适应（记录各策略成功率，动态调整选择权重）
7. [P2] 失败模式学习（分析失败原因 → 生成排除规则）
8. [P2] `--learn` 参数支持
9. [P2] 失败熔断与降级机制

**不做**:
- 模型微调（fine-tuning）
- 本地部署 LLM
- 向量数据库（使用简单的 JSON 文件存储 + 余弦相似度）

**完成标准**:
- [ ] `python mda_extractor.py --learn` 可运行
- [ ] LLM 客户端支持 ≥ 3 个提供商（DeepSeek/Qwen/Claude）
- [ ] Self-Refine 循环最多 3 次
- [ ] 成功案例自动入库 `extraction_rules`
- [ ] 失败案例标记 `needs_review=true`
- [ ] API 失败时自动降级到 CPU 策略

---

## P1: 技术调研

### 1.1 现有基础设施分析

| 组件 | 状态 | 可复用性 |
|------|------|----------|
| `scripts/llm_annotate.py` | 已存在 | 可复用 Prompt 模板思路 |
| `extraction_rules` 表 | 已存在 | 直接使用 |
| `scorer.py` | 已存在 | 可复用评分逻辑 |
| `strategies.py` | 已存在 | 需扩展支持自定义规则优先 |
| `mda_extractor.py` | 已存在 | 需添加 `--learn` 参数 |

### 1.2 LLM 提供商 API 调研

| 提供商 | SDK | 定价 | 中文能力 | 备注 |
|--------|-----|------|----------|------|
| DeepSeek | openai-compatible | ~0.14元/1M tokens | 优 | 推荐批量任务 |
| Qwen (通义千问) | dashscope | ~0.2元/1M tokens | 优 | 阿里云生态 |
| Claude | anthropic | ~$3/1M tokens | 良 | 理解能力强 |
| GPT-4o-mini | openai | ~$0.15/1M tokens | 中 | 通用能力强 |

**技术选型决策**:
- 使用 `httpx` 异步客户端统一封装
- OpenAI-compatible 接口优先（DeepSeek, Qwen 兼容）
- Claude 使用 `anthropic` SDK
- 通过环境变量配置 API Key

### 1.3 动态 Few-shot 实现方案

**方案对比**:

| 方案 | 优点 | 缺点 | 选择 |
|------|------|------|------|
| 向量数据库 (ChromaDB/Milvus) | 检索效率高 | 额外依赖 | ❌ |
| 简单 JSON + 余弦相似度 | 零依赖，易实现 | 大规模效率低 | ✅ |
| DuckDB FTS | 内置全文搜索 | 语义理解弱 | 备选 |

**选定方案**: JSON 文件存储 + Jaccard 相似度（关键词集合匹配）

> **设计决策**: 选择 Jaccard 而非 TF-IDF，因为:
> 1. 年报关键词集合规模有限（~10-20 词），Jaccard 计算效率高
> 2. 无需引入 scikit-learn 等额外依赖
> 3. 实测效果满足需求，可后续升级

```json
// data/success_samples.json
{
  "samples": [
    {
      "stock_code": "600519",
      "year": 2023,
      "industry": "白酒",
      "toc_signature": "hash...",
      "start_pattern": "第三节 管理层讨论与分析",
      "end_pattern": "第四节 公司治理",
      "keywords": ["收入", "同比", "毛利率", "现金流"],
      "char_count": 15000,
      "quality_score": 95
    }
  ]
}
```

### 1.4 Self-Refine 流程设计

```
初始提取
    ↓
LLM-as-Judge 评估
    ↓
评分 ≥ 阈值? ──是──→ 成功，存入样本库
    │
    否 (评分 < 阈值)
    ↓
构建 Refine Prompt:
  - 当前提取结果
  - 评估反馈 (遗漏/噪音/边界错误)
  - 改进建议
    ↓
LLM 生成修正后的 start/end pattern
    ↓
重新提取 (最多 N 次)
    ↓
仍失败? ──是──→ 记录失败模式，标记 needs_review
```

### 1.5 策略权重自适应

**数据结构**:
```python
# 记录在 DuckDB 或 JSON
strategy_stats = {
    "generic": {"attempts": 100, "success": 85},
    "toc": {"attempts": 50, "success": 45},
    "custom": {"attempts": 30, "success": 28},
    "llm_learned": {"attempts": 20, "success": 18}
}
```

**权重计算**:
```python
def calculate_weight(strategy: str) -> float:
    stats = strategy_stats[strategy]
    success_rate = stats["success"] / max(stats["attempts"], 1)
    # 加入探索因子，避免过度偏向
    exploration_bonus = 1 / (stats["attempts"] + 10)
    return success_rate + exploration_bonus
```

---

## P2: 设计规格

### 2.1 模块架构

```
annual_report_mda/
├── llm/                           # 新增 - LLM 相关模块
│   ├── __init__.py
│   ├── client.py                  # 统一 LLM 客户端
│   ├── providers/                 # 各提供商适配器
│   │   ├── __init__.py
│   │   ├── base.py                # 基类
│   │   ├── deepseek.py
│   │   ├── qwen.py
│   │   ├── claude.py
│   │   └── openai.py
│   ├── prompts.py                 # Prompt 模板
│   └── rate_limiter.py            # 限流器
├── adaptive/                      # 新增 - 自适应学习模块
│   ├── __init__.py
│   ├── self_refine.py             # Self-Refine 循环
│   ├── few_shot.py                # 动态 Few-shot
│   ├── strategy_weights.py        # 策略权重
│   ├── failure_patterns.py        # 失败模式分析
│   └── sample_store.py            # 样本存储
├── strategies.py                  # 现有 - 需扩展
├── scorer.py                      # 现有
└── db.py                          # 现有
```

### 2.2 LLM 客户端接口

```python
# annual_report_mda/llm/client.py

from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Optional
import httpx

@dataclass
class LLMResponse:
    """LLM 响应结构"""
    content: str
    model: str
    provider: str
    usage: dict  # {"prompt_tokens": N, "completion_tokens": M}
    latency_ms: int
    raw_response: Optional[dict] = None

class LLMProvider(ABC):
    """LLM 提供商基类"""

    @property
    @abstractmethod
    def name(self) -> str:
        """提供商名称"""
        ...

    @abstractmethod
    async def complete(
        self,
        prompt: str,
        *,
        system: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: int = 4096,
        timeout: float = 60.0,
    ) -> LLMResponse:
        """执行补全请求"""
        ...

    @abstractmethod
    def is_available(self) -> bool:
        """检查 API Key 是否配置"""
        ...

class LLMClient:
    """统一 LLM 客户端，支持多提供商降级"""

    def __init__(
        self,
        providers: list[str] = None,
        fallback_order: list[str] = None,
    ):
        """
        Args:
            providers: 启用的提供商列表，默认全部
            fallback_order: 降级顺序，默认 ["deepseek", "qwen", "claude", "openai"]
        """
        ...

    async def complete(
        self,
        prompt: str,
        *,
        system: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: int = 4096,
        provider: Optional[str] = None,
        retry_on_failure: bool = True,
    ) -> LLMResponse:
        """
        执行补全，失败时自动降级到下一个提供商。

        Args:
            prompt: 用户 Prompt
            system: 系统 Prompt
            temperature: 采样温度
            max_tokens: 最大生成长度
            provider: 指定提供商，None 则按优先级选择
            retry_on_failure: 是否在失败时重试其他提供商

        Returns:
            LLMResponse

        Raises:
            LLMAllProvidersFailedError: 所有提供商均失败
        """
        ...
```

### 2.3 Prompt 模板

```python
# annual_report_mda/llm/prompts.py

ANALYZE_TOC_PROMPT = """分析以下年报目录结构，识别"管理层讨论与分析"(MD&A) 章节的边界。

## 年报信息
- 股票代码: {stock_code}
- 年份: {year}
- 行业: {industry}

## 目录内容
{toc_content}

## 任务
1. 找出 MD&A 章节的起始标题（通常是"第X节 管理层讨论与分析"或"第X节 董事会报告"）
2. 找出下一章节的标题作为结束边界
3. 提取目录中标注的页码范围

## 输出格式 (JSON)
```json
{
  "start_pattern": "章节标题正则表达式",
  "end_pattern": "下一章节标题正则表达式",
  "toc_start_page": 起始页码,
  "toc_end_page": 结束页码,
  "confidence": 0.0-1.0,
  "reasoning": "判断依据"
}
```
"""

SELF_REFINE_PROMPT = """你之前的 MD&A 提取结果存在问题，请根据反馈进行改进。

## 当前提取结果
- 起始标题: {current_start}
- 结束标题: {current_end}
- 提取文本长度: {char_count} 字符
- 质量评分: {quality_score}/100

## 评估反馈
{evaluation_feedback}

## 问题诊断
{problem_diagnosis}

## 年报原文片段 (前后文)
{context_snippet}

## 任务
根据以上反馈，修正起始和结束标题模式。

## 输出格式 (JSON)
```json
{
  "refined_start_pattern": "修正后的起始标题",
  "refined_end_pattern": "修正后的结束标题",
  "changes_made": "做了哪些修改",
  "expected_improvement": "预期改进效果"
}
```
"""

EVALUATE_EXTRACTION_PROMPT = """评估以下 MD&A 提取结果的质量。

## 提取结果
- 股票代码: {stock_code}
- 年份: {year}
- 字符数: {char_count}
- 使用策略: {used_rule_type}

## 提取文本 (前 5000 字符)
{mda_text_preview}

## 评估维度
1. **完整性** (0-30分): MD&A 内容是否完整，有无明显遗漏
2. **准确性** (0-30分): 边界是否准确，有无包含无关内容（如财务报表、目录页）
3. **清洁度** (0-20分): 有无噪音（表格残留、页眉页脚、乱码）
4. **结构性** (0-20分): 是否保持原文结构，段落分隔是否合理

## 输出格式 (JSON)
```json
{
  "scores": {
    "completeness": N,
    "accuracy": N,
    "cleanliness": N,
    "structure": N
  },
  "total_score": N,
  "issues": ["问题1", "问题2"],
  "suggestions": ["改进建议1", "改进建议2"],
  "pass": true/false
}
```
"""
```

### 2.4 Self-Refine 模块

```python
# annual_report_mda/adaptive/self_refine.py

from dataclasses import dataclass
from typing import Optional
import logging

from annual_report_mda.llm.client import LLMClient, LLMResponse
from annual_report_mda.llm.prompts import SELF_REFINE_PROMPT, EVALUATE_EXTRACTION_PROMPT
from annual_report_mda.strategies import ExtractionResult, extract_mda_iterative

_LOG = logging.getLogger(__name__)

@dataclass
class RefineResult:
    """Self-Refine 结果"""
    success: bool
    extraction: Optional[ExtractionResult]
    iterations: int
    final_score: float
    history: list[dict]  # 每轮的 score 和 feedback

class SelfRefineLoop:
    """Self-Refine 循环控制器"""

    def __init__(
        self,
        llm_client: LLMClient,
        max_iterations: int = 3,
        score_threshold: float = 70.0,
    ):
        self.llm = llm_client
        self.max_iterations = max_iterations
        self.score_threshold = score_threshold

    async def refine(
        self,
        pages: list[str],
        stock_code: str,
        year: int,
        *,
        initial_extraction: Optional[ExtractionResult] = None,
        industry: Optional[str] = None,
    ) -> RefineResult:
        """
        执行 Self-Refine 循环。

        流程:
        1. 初始提取（如果未提供）
        2. LLM 评估质量
        3. 如果评分 >= 阈值，成功返回
        4. 否则，LLM 生成改进建议
        5. 使用改进后的 pattern 重新提取
        6. 重复 2-5，最多 max_iterations 次

        Args:
            pages: 年报文本页面列表
            stock_code: 股票代码
            year: 年份
            initial_extraction: 初始提取结果（可选）
            industry: 行业（用于上下文）

        Returns:
            RefineResult
        """
        history = []
        current_extraction = initial_extraction
        current_start_pattern = None
        current_end_pattern = None

        # 获取 event loop 用于 run_in_executor
        loop = asyncio.get_event_loop()

        for iteration in range(self.max_iterations):
            # 1. 如果没有提取结果，执行初始提取
            # 注意: extract_mda_iterative 是 CPU 密集型同步函数，
            # 必须使用 run_in_executor 避免阻塞 event loop
            if current_extraction is None:
                current_extraction = await loop.run_in_executor(
                    None,  # 使用默认线程池
                    lambda: extract_mda_iterative(
                        pages,
                        custom_start_pattern=current_start_pattern,
                        custom_end_pattern=current_end_pattern,
                    )
                )

            if current_extraction is None:
                _LOG.warning("提取失败，无法进行 refine")
                return RefineResult(
                    success=False,
                    extraction=None,
                    iterations=iteration + 1,
                    final_score=0.0,
                    history=history,
                )

            # 2. LLM 评估
            evaluation = await self._evaluate(current_extraction, stock_code, year)
            score = evaluation.get("total_score", 0)

            history.append({
                "iteration": iteration + 1,
                "score": score,
                "issues": evaluation.get("issues", []),
                "start_pattern": current_start_pattern,
                "end_pattern": current_end_pattern,
            })

            # 3. 检查是否通过
            if score >= self.score_threshold:
                _LOG.info(f"Refine 成功: iteration={iteration + 1}, score={score}")
                return RefineResult(
                    success=True,
                    extraction=current_extraction,
                    iterations=iteration + 1,
                    final_score=score,
                    history=history,
                )

            # 4. 生成改进建议
            if iteration < self.max_iterations - 1:
                refinement = await self._get_refinement(
                    current_extraction,
                    evaluation,
                    pages,
                    stock_code,
                    year,
                )

                current_start_pattern = refinement.get("refined_start_pattern")
                current_end_pattern = refinement.get("refined_end_pattern")
                current_extraction = None  # 重置，下一轮重新提取

        # 达到最大迭代次数
        return RefineResult(
            success=False,
            extraction=current_extraction,
            iterations=self.max_iterations,
            final_score=history[-1]["score"] if history else 0.0,
            history=history,
        )

    async def _evaluate(
        self,
        extraction: ExtractionResult,
        stock_code: str,
        year: int,
    ) -> dict:
        """使用 LLM 评估提取质量"""
        prompt = EVALUATE_EXTRACTION_PROMPT.format(
            stock_code=stock_code,
            year=year,
            char_count=len(extraction.mda_raw),
            used_rule_type=extraction.used_rule_type,
            mda_text_preview=extraction.mda_raw[:5000],
        )

        response = await self.llm.complete(prompt, temperature=0.3)
        return self._parse_json_response(response.content)

    async def _get_refinement(
        self,
        extraction: ExtractionResult,
        evaluation: dict,
        pages: list[str],
        stock_code: str,
        year: int,
    ) -> dict:
        """使用 LLM 生成改进建议"""
        # 获取上下文片段
        context = self._get_context_snippet(pages, extraction)

        prompt = SELF_REFINE_PROMPT.format(
            current_start=extraction.hit_start,
            current_end=extraction.hit_end,
            char_count=len(extraction.mda_raw),
            quality_score=evaluation.get("total_score", 0),
            evaluation_feedback="\n".join(evaluation.get("issues", [])),
            problem_diagnosis="\n".join(evaluation.get("suggestions", [])),
            context_snippet=context,
        )

        response = await self.llm.complete(prompt, temperature=0.5)
        return self._parse_json_response(response.content)

    def _get_context_snippet(
        self,
        pages: list[str],
        extraction: ExtractionResult,
    ) -> str:
        """获取提取边界附近的上下文"""
        start_idx = max(0, extraction.page_index_start - 1)
        end_idx = min(len(pages), extraction.page_index_end + 1)

        snippet_parts = []
        for i in range(start_idx, min(start_idx + 2, len(pages))):
            snippet_parts.append(f"=== 第 {i+1} 页 ===\n{pages[i][:1000]}")

        snippet_parts.append("... [中间内容省略] ...")

        for i in range(max(start_idx + 2, end_idx - 2), end_idx):
            snippet_parts.append(f"=== 第 {i+1} 页 ===\n{pages[i][-1000:]}")

        return "\n\n".join(snippet_parts)

    def _parse_json_response(self, content: str) -> dict:
        """解析 LLM 返回的 JSON，失败时抛出异常"""
        import json
        import re

        # 提取 JSON 代码块
        json_match = re.search(r"```json\s*(.*?)\s*```", content, re.DOTALL)
        if json_match:
            content = json_match.group(1)

        try:
            return json.loads(content)
        except json.JSONDecodeError as e:
            # 不静默失败，抛出明确异常终止当前迭代
            raise LLMJSONParseError(
                f"无法解析 LLM 返回的 JSON: {e}\n原始内容: {content[:500]}"
            ) from e


class LLMJSONParseError(Exception):
    """LLM 返回的 JSON 解析失败"""
    pass
```

### 2.5 动态 Few-shot 模块

```python
# annual_report_mda/adaptive/few_shot.py

from dataclasses import dataclass
from pathlib import Path
from typing import Optional
import json
import math

@dataclass
class FewShotSample:
    """Few-shot 样本"""
    stock_code: str
    year: int
    industry: str
    toc_signature: str  # 目录结构哈希，用于匹配相似版式
    start_pattern: str
    end_pattern: str
    keywords: list[str]
    quality_score: float
    char_count: int

class FewShotStore:
    """Few-shot 样本存储"""

    def __init__(self, store_path: str = "data/success_samples.json"):
        self.store_path = Path(store_path)
        self._samples: list[FewShotSample] = []
        self._load()

    def _load(self) -> None:
        """加载样本库"""
        if self.store_path.exists():
            with open(self.store_path, encoding="utf-8") as f:
                data = json.load(f)
                self._samples = [FewShotSample(**s) for s in data.get("samples", [])]

    def save(self) -> None:
        """保存样本库"""
        self.store_path.parent.mkdir(parents=True, exist_ok=True)
        data = {
            "version": "1.0",
            "samples": [s.__dict__ for s in self._samples]
        }
        with open(self.store_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    def add(self, sample: FewShotSample) -> None:
        """添加样本"""
        # 检查是否已存在
        for i, s in enumerate(self._samples):
            if s.stock_code == sample.stock_code and s.year == sample.year:
                self._samples[i] = sample  # 更新
                return
        self._samples.append(sample)

    def find_similar(
        self,
        keywords: list[str],
        industry: Optional[str] = None,
        top_k: int = 3,
    ) -> list[FewShotSample]:
        """
        查找相似样本。

        使用 Jaccard 相似度匹配关键词，优先同行业。

        Args:
            keywords: 目标文档关键词
            industry: 目标行业
            top_k: 返回数量

        Returns:
            相似度最高的 top_k 个样本
        """
        if not self._samples:
            return []

        scored = []
        target_set = set(keywords)

        for sample in self._samples:
            sample_set = set(sample.keywords)

            # Jaccard 相似度
            intersection = len(target_set & sample_set)
            union = len(target_set | sample_set)
            jaccard = intersection / union if union > 0 else 0

            # 同行业加分
            industry_bonus = 0.2 if industry and sample.industry == industry else 0

            # 质量评分权重
            quality_weight = sample.quality_score / 100.0

            score = jaccard * quality_weight + industry_bonus
            scored.append((score, sample))

        scored.sort(key=lambda x: -x[0])
        return [s for _, s in scored[:top_k]]

    def format_few_shot_prompt(self, samples: list[FewShotSample]) -> str:
        """格式化 few-shot 示例"""
        if not samples:
            return ""

        lines = ["以下是相似年报的成功提取案例：\n"]

        for i, sample in enumerate(samples, 1):
            lines.append(f"### 案例 {i}: {sample.stock_code} ({sample.year})")
            lines.append(f"- 行业: {sample.industry}")
            lines.append(f"- 起始标题: `{sample.start_pattern}`")
            lines.append(f"- 结束标题: `{sample.end_pattern}`")
            lines.append(f"- 提取字数: {sample.char_count}")
            lines.append(f"- 质量评分: {sample.quality_score}\n")

        return "\n".join(lines)
```

### 2.6 策略权重自适应

```python
# annual_report_mda/adaptive/strategy_weights.py

from pathlib import Path
from typing import Optional
import json
import random

class StrategyWeights:
    """策略权重管理器"""

    STRATEGIES = ["generic", "toc", "custom", "llm_learned"]

    def __init__(self, store_path: str = "data/strategy_stats.json"):
        self.store_path = Path(store_path)
        self._stats: dict[str, dict[str, int]] = {}
        self._load()

    def _load(self) -> None:
        """加载统计数据"""
        if self.store_path.exists():
            with open(self.store_path, encoding="utf-8") as f:
                self._stats = json.load(f)
        else:
            self._stats = {s: {"attempts": 0, "success": 0} for s in self.STRATEGIES}

    def save(self) -> None:
        """保存统计数据"""
        self.store_path.parent.mkdir(parents=True, exist_ok=True)
        with open(self.store_path, "w", encoding="utf-8") as f:
            json.dump(self._stats, f, indent=2)

    def record(self, strategy: str, success: bool) -> None:
        """记录策略执行结果"""
        if strategy not in self._stats:
            self._stats[strategy] = {"attempts": 0, "success": 0}

        self._stats[strategy]["attempts"] += 1
        if success:
            self._stats[strategy]["success"] += 1

    def get_weight(self, strategy: str) -> float:
        """
        计算策略权重。

        公式: success_rate + exploration_bonus
        exploration_bonus = 1 / (attempts + 10)
        """
        if strategy not in self._stats:
            return 0.5  # 未知策略默认权重

        stats = self._stats[strategy]
        attempts = stats["attempts"]
        success = stats["success"]

        success_rate = success / max(attempts, 1)
        exploration_bonus = 1 / (attempts + 10)

        return success_rate + exploration_bonus

    def select_strategy(self, available: list[str] = None) -> str:
        """
        基于权重选择策略（带探索）。

        使用 softmax 采样，保证探索性。
        """
        if available is None:
            available = self.STRATEGIES

        weights = [self.get_weight(s) for s in available]
        total = sum(weights)

        if total == 0:
            return random.choice(available)

        probs = [w / total for w in weights]
        return random.choices(available, weights=probs, k=1)[0]

    def get_priority_order(self) -> list[str]:
        """获取策略优先级排序"""
        return sorted(self.STRATEGIES, key=lambda s: -self.get_weight(s))
```

### 2.7 失败模式学习

```python
# annual_report_mda/adaptive/failure_patterns.py

from dataclasses import dataclass
from pathlib import Path
from typing import Optional
import json
import re

@dataclass
class FailurePattern:
    """失败模式"""
    pattern_id: str
    description: str
    match_conditions: dict  # 匹配条件
    exclusion_rule: str  # 排除规则
    occurrences: int  # 出现次数

class FailurePatternStore:
    """失败模式存储"""

    def __init__(self, store_path: str = "data/failure_patterns.json"):
        self.store_path = Path(store_path)
        self._patterns: list[FailurePattern] = []
        self._load()

    def _load(self) -> None:
        if self.store_path.exists():
            with open(self.store_path, encoding="utf-8") as f:
                data = json.load(f)
                self._patterns = [FailurePattern(**p) for p in data.get("patterns", [])]

    def save(self) -> None:
        self.store_path.parent.mkdir(parents=True, exist_ok=True)
        data = {
            "version": "1.0",
            "patterns": [p.__dict__ for p in self._patterns]
        }
        with open(self.store_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    def add_failure(
        self,
        stock_code: str,
        year: int,
        error_type: str,
        error_message: str,
        extraction_result: Optional[dict] = None,
    ) -> None:
        """添加失败记录，自动归类模式"""
        # 简单模式匹配
        pattern_id = self._classify_failure(error_type, error_message)

        for p in self._patterns:
            if p.pattern_id == pattern_id:
                p.occurrences += 1
                return

        # 新模式
        self._patterns.append(FailurePattern(
            pattern_id=pattern_id,
            description=f"{error_type}: {error_message[:100]}",
            match_conditions={"error_type": error_type},
            exclusion_rule="",  # 待 LLM 分析
            occurrences=1,
        ))

    def _classify_failure(self, error_type: str, error_message: str) -> str:
        """简单失败分类"""
        if "目录" in error_message or "TOC" in error_message:
            return "TOC_PARSE_FAILED"
        if "边界" in error_message or "boundary" in error_message.lower():
            return "BOUNDARY_DETECTION_FAILED"
        if "空" in error_message or "empty" in error_message.lower():
            return "EMPTY_RESULT"
        if "乱码" in error_message or "garbled" in error_message.lower():
            return "ENCODING_ERROR"
        return f"OTHER_{error_type}"

    def get_exclusion_prompts(self) -> list[str]:
        """获取排除提示（用于负面 prompt）"""
        prompts = []
        for p in self._patterns:
            if p.exclusion_rule and p.occurrences >= 3:
                prompts.append(f"避免: {p.exclusion_rule}")
        return prompts
```

### 2.8 数据库扩展

```python
# 新增表: strategy_stats (在 db.py 中添加)

def _create_tables(conn):
    # ... 现有表 ...

    # 策略统计表
    conn.execute("""
        CREATE TABLE IF NOT EXISTS strategy_stats (
            strategy VARCHAR PRIMARY KEY,
            attempts INTEGER DEFAULT 0,
            success INTEGER DEFAULT 0,
            last_updated TIMESTAMP
        );
    """)

    # LLM 调用日志表
    conn.execute("""
        CREATE TABLE IF NOT EXISTS llm_call_logs (
            id INTEGER PRIMARY KEY,
            stock_code VARCHAR,
            year INTEGER,
            provider VARCHAR,
            prompt_type VARCHAR,
            prompt_tokens INTEGER,
            completion_tokens INTEGER,
            latency_ms INTEGER,
            success BOOLEAN,
            error_message TEXT,
            created_at TIMESTAMP
        );
    """)
```

### 2.9 命令行参数扩展

```python
# mda_extractor.py 扩展

def _build_parser():
    # ... 现有参数 ...

    # LLM 自适应学习参数组
    learn_group = parser.add_argument_group("LLM 自适应学习")
    learn_group.add_argument(
        "--learn",
        action="store_true",
        help="启用 LLM 自适应学习模式，失败时自动调用 LLM 改进",
    )
    learn_group.add_argument(
        "--llm-provider",
        choices=["deepseek", "qwen", "claude", "openai", "auto"],
        default="auto",
        help="LLM 提供商 (默认 auto，按优先级降级)",
    )
    learn_group.add_argument(
        "--max-refine",
        type=int,
        default=3,
        help="Self-Refine 最大迭代次数 (默认 3)",
    )
    learn_group.add_argument(
        "--score-threshold",
        type=float,
        default=70.0,
        help="质量评分阈值，低于此值触发 refine (默认 70)",
    )
    learn_group.add_argument(
        "--save-rules",
        action="store_true",
        help="将成功的 LLM 规则保存到 extraction_rules 表",
    )

    return parser
```

---

## 实现清单

### Phase A: 基础设施 (估算 2-3 天)

#### Step A1: LLM 客户端基础
- [ ] 创建 `annual_report_mda/llm/` 目录结构
- [ ] 实现 `LLMProvider` 基类和 `LLMResponse` 数据类
- [ ] 实现 `DeepSeekProvider` (OpenAI-compatible)
- [ ] 实现 `QwenProvider` (dashscope)
- [ ] 实现 `ClaudeProvider` (anthropic)
- [ ] 实现 `OpenAIProvider` (openai)
- [ ] 实现统一 `LLMClient` 类（支持降级）
- [ ] 添加速率限制器 `rate_limiter.py`
- [ ] 编写单元测试

#### Step A2: Prompt 模板
- [ ] 实现 `ANALYZE_TOC_PROMPT`
- [ ] 实现 `SELF_REFINE_PROMPT`
- [ ] 实现 `EVALUATE_EXTRACTION_PROMPT`
- [ ] 添加 Prompt 格式化工具函数

### Phase B: 自适应学习核心 (估算 3-4 天)

#### Step B1: Self-Refine 模块
- [ ] 创建 `annual_report_mda/adaptive/` 目录结构
- [ ] 实现 `SelfRefineLoop` 类
- [ ] 实现 `_evaluate()` 方法
- [ ] 实现 `_get_refinement()` 方法
- [ ] 编写单元测试

#### Step B2: Few-shot 模块
- [ ] 实现 `FewShotSample` 和 `FewShotStore`
- [ ] 实现 `find_similar()` 方法（Jaccard 相似度）
- [ ] 实现 `format_few_shot_prompt()` 方法
- [ ] 编写单元测试

#### Step B3: 策略权重模块
- [ ] 实现 `StrategyWeights` 类
- [ ] 实现 `record()` 和 `get_weight()` 方法
- [ ] 实现 `select_strategy()` 方法（softmax 采样）
- [ ] 编写单元测试

#### Step B4: 失败模式模块
- [ ] 实现 `FailurePattern` 和 `FailurePatternStore`
- [ ] 实现 `add_failure()` 和自动分类
- [ ] 实现 `get_exclusion_prompts()` 方法
- [ ] 编写单元测试

### Phase C: 集成与命令行 (估算 2 天)

#### Step C1: 数据库扩展
- [ ] 添加 `strategy_stats` 表
- [ ] 添加 `llm_call_logs` 表
- [ ] 更新 `data/schema.json`

#### Step C2: 提取器集成
- [ ] 扩展 `mda_extractor.py` 命令行参数
- [ ] 实现 `--learn` 模式逻辑
- [ ] 集成 Self-Refine 循环
- [ ] 集成 Few-shot 检索
- [ ] 集成策略权重选择
- [ ] 实现规则写入 `extraction_rules` 表

**规则持久化详细逻辑**:

```python
# 规则写入逻辑 (在 mda_extractor.py 或 adaptive/rule_writer.py)

async def save_learned_rule(
    conn: "duckdb.DuckDBPyConnection",
    stock_code: str,
    year: int,
    start_pattern: str,
    end_pattern: str,
    toc_signature: str,
) -> None:
    """
    将 LLM 学习到的规则保存到 extraction_rules 表。

    规则类型:
    - 'single': 仅适用于特定 (stock_code, year) 的单次规则
    - 'generalized': 可复用到相同 toc_signature 的通用规则 (未来扩展)

    当前实现采用 'single' 模式，确保规则精确匹配。
    """
    from annual_report_mda.utils import utc_now

    conn.execute(
        """
        INSERT INTO extraction_rules (
            stock_code, year, report_signature,
            start_pattern, end_pattern,
            rule_source, updated_at
        )
        VALUES (?, ?, ?, ?, ?, 'llm_learned', ?)
        ON CONFLICT (stock_code, year) DO UPDATE SET
            start_pattern = EXCLUDED.start_pattern,
            end_pattern = EXCLUDED.end_pattern,
            report_signature = EXCLUDED.report_signature,
            rule_source = EXCLUDED.rule_source,
            updated_at = EXCLUDED.updated_at;
        """,
        (stock_code, year, toc_signature, start_pattern, end_pattern, utc_now()),
    )


# 调用时机: RefineResult.success == True 且 --save-rules 启用
if refine_result.success and args.save_rules:
    await save_learned_rule(
        conn,
        stock_code=stock_code,
        year=year,
        start_pattern=refine_result.extraction.hit_start,
        end_pattern=refine_result.extraction.hit_end,
        toc_signature=compute_toc_signature(pages),
    )
    _LOG.info(f"已保存 LLM 学习规则: {stock_code}/{year}")
```

#### Step C3: 熔断与降级
- [ ] 实现 API 调用熔断逻辑（连续失败 N 次后暂停）
- [ ] 实现降级逻辑（LLM 失败时回退 CPU 策略）
- [ ] 添加重试机制（指数退避）

### Phase D: 测试与文档 (估算 1-2 天)

#### Step D1: 测试
- [ ] 编写 LLM 客户端单元测试（使用 Mock）
- [ ] 编写 Self-Refine 集成测试
- [ ] 编写 Few-shot 单元测试
- [ ] 编写策略权重单元测试
- [ ] 编写端到端测试

#### Step D2: 文档
- [ ] 更新 README.md，添加 `--learn` 使用说明
- [ ] 更新 CLAUDE.md，添加新模块说明
- [ ] 编写配置环境变量说明（API Keys）

---

## 验收标准

### 功能验收（必须通过）

| ID | 验收项 | Given | When | Then | 状态 |
|----|--------|-------|------|------|------|
| A1 | LLM 客户端 | API Key 配置正确 | 调用任意 LLM | 返回 `LLMResponse` 对象 | ⏳ |
| A2 | 多提供商降级 | 主提供商 API 失败 | 调用 LLM | 自动切换到下一提供商 | ⏳ |
| A3 | Self-Refine | 初次提取评分 < 70 | 启用 `--learn` | 最多迭代 3 次，每轮评分提升 | ⏳ |
| A4 | 规则保存 | LLM 学习成功 | 启用 `--save-rules` | `extraction_rules` 表新增记录 | ⏳ |
| A5 | 策略权重 | 已有历史统计 | 选择策略 | 高成功率策略优先 | ⏳ |
| A6 | 熔断降级 | LLM 连续失败 5 次 | 继续调用 | 自动降级到 CPU 策略 | ⏳ |

### 质量验收（建议通过）

| ID | 验收项 | 指标 | 状态 |
|----|--------|------|------|
| Q1 | LLM 调用延迟 | 平均 < 10s | ⏳ |
| Q2 | Self-Refine 成功率 | ≥ 50% 的失败案例通过 refine 修复 | ⏳ |
| Q3 | 单元测试覆盖率 | `llm/` 和 `adaptive/` 模块 ≥ 70% | ⏳ |
| Q4 | 代码规范 | `ruff check` 零警告 | ⏳ |

### 测试命令

```bash
# 运行 LLM 客户端测试
pytest tests/test_llm_client.py -v

# 运行自适应学习测试
pytest tests/test_adaptive_*.py -v

# 端到端测试 (需要真实 API Key)
python mda_extractor.py --learn --text data/sample.txt --dry-run

# 测试降级逻辑
LLM_PROVIDER=invalid python mda_extractor.py --learn --text data/sample.txt
```

---

## 风险与缓解

| 风险 | 影响 | 缓解措施 |
|------|------|----------|
| LLM API 成本失控 | 预算超支 | 添加日 API 调用上限配置 |
| LLM 返回格式不稳定 | 解析失败 | 多重 JSON 提取策略 + 兜底处理 |
| Self-Refine 死循环 | 资源浪费 | 硬性 max_iterations 限制 |
| 多提供商 SDK 冲突 | 依赖问题 | 可选依赖，按需安装 |

---

## 依赖管理

### 新增依赖

```txt
# requirements-llm.txt (可选，LLM 功能)
httpx>=0.25.0
anthropic>=0.18.0  # Claude
openai>=1.0.0      # OpenAI 兼容 (DeepSeek, Qwen)
dashscope>=1.0.0   # 阿里云通义千问
```

### 环境变量

```bash
# .env.example
DEEPSEEK_API_KEY=your_key_here
QWEN_API_KEY=your_key_here
ANTHROPIC_API_KEY=your_key_here
OPENAI_API_KEY=your_key_here

# 可选配置
LLM_DAILY_LIMIT=1000  # 每日 API 调用上限
LLM_RATE_LIMIT=10     # 每分钟请求数限制
```

---

## 附录: 配置文件扩展

```yaml
# config.yaml 新增 llm 配置段
llm:
  enabled: true
  providers:
    - deepseek
    - qwen
    - claude
  fallback_order:
    - deepseek
    - qwen
    - claude

  rate_limit:
    requests_per_minute: 10
    daily_limit: 1000

  self_refine:
    max_iterations: 3
    score_threshold: 70.0

  few_shot:
    store_path: data/success_samples.json
    top_k: 3

  circuit_breaker:
    failure_threshold: 5
    cooldown_seconds: 300
```
