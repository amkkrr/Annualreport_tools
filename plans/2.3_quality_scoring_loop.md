---
task_id: quality-scoring-loop
type: FEAT
complexity: S
current_phase: DONE
completed_phases: [P0, P1, P2, P3, P4, IMPL]
branch: null
audit_iteration: 0
created_at: 2026-01-10
updated_at: 2026-01-10
---

# 2.3 质量评分闭环

## 问题定义 (P0)

**类型**: FEAT-S

**背景**: 当前评分器 `scorer.py` 仅有基础的关键词命中率检测，缺少负向特征检测（表格残留、页眉干扰、乱码比例），且数据库无独立的 `quality_score` 字段和 `needs_review` 标记，无法建立质量反馈闭环。

**范围**:
- 做:
  - 升级 `scorer.py`，增加负向特征检测维度
  - 在 `mda_text` 表新增 `quality_score` (INTEGER 0-100) 和 `needs_review` (BOOLEAN) 字段
  - 提取完成后自动计算 `quality_score`，低分样本自动标记 `needs_review = true`
  - 更新 schema.json 和相关文档
- 不做:
  - 不修改提取策略逻辑本身
  - 不实现 LLM 自适应学习（属于 Phase 2.5）
  - 不实现 Web UI 或可视化

**完成标准**:
- [ ] `scorer.py` 支持负向特征检测：表格残留、页眉干扰、乱码比例
- [ ] `mda_text` 表含 `quality_score` 和 `needs_review` 字段
- [ ] 提取流程自动填充这两个字段
- [ ] 低分阈值 (quality_score < 60) 自动设置 `needs_review = true`
- [ ] 新增 `mda_needs_review` 视图，便于查询待审核样本

---

## 技术调研 (P1)

### 1. 技术可行性

**负向特征检测方案**:

| 特征 | 检测方法 | 扣分权重 |
|------|---------|---------|
| 表格残留 | 连续数字行检测 (3行以上纯数字/小数) | -15 |
| 页眉干扰 | 重复短行检测 (同一短行出现 >3 次) | -10 |
| 乱码比例 | 非中文/英文/数字/标点字符占比 >5% | -20 |
| 目录引导线 | 已有检测 (`...`/`…`)，保留 | -20 |
| 长度异常 | 已有检测，保留 | -10 |
| 锚点缺失 | 已有检测，保留 | -15 |
| 尾部重叠 | 已有检测，保留 | -10 |

**评分模型**:
```
base_score = 100
for each detected_issue:
    base_score -= penalty[issue]
quality_score = max(0, base_score)
```

### 2. 影响分析

| 文件 | 改动类型 | 风险等级 |
|------|---------|---------|
| `annual_report_mda/scorer.py` | 修改 | 低 |
| `annual_report_mda/db.py` | 修改 | 中 |
| `annual_report_mda/data_manager.py` | 修改 | 中 |
| `mda_extractor.py` | 修改 | 低 |
| `data/schema.json` | 修改 | 低 |

### 3. 边界条件

| 场景 | 处理方式 |
|------|---------|
| 空文本 | quality_score = 0, needs_review = true |
| 极短文本 (<500字) | 触发 FLAG_LENGTH_ABNORMAL, 扣 10 分 |
| 提取失败 | quality_score = 0, needs_review = true |
| 所有特征均触发 | 最低分 0，不为负 |

---

## 设计规格 (P2)

### 1. 评分模型设计

**新增负向特征检测函数**:

```python
# scorer.py

@dataclass(frozen=True)
class NegativeFeatures:
    """负向特征检测结果"""
    table_residue_score: int  # 表格残留扣分 (0 or 15)
    header_noise_score: int   # 页眉干扰扣分 (0 or 10)
    garbled_ratio: float      # 乱码比例 (0.0-1.0)
    garbled_penalty: int      # 乱码扣分 (0 or 20)

    table_residue_lines: int  # 检测到的表格行数
    repeated_headers: list[str]  # 检测到的重复页眉


def detect_negative_features(text: str) -> NegativeFeatures:
    """
    检测文本中的负向特征。

    Args:
        text: MD&A 文本

    Returns:
        NegativeFeatures: 包含各负向特征检测结果
    """


def detect_table_residue(text: str) -> tuple[bool, int]:
    """
    检测表格残留（连续数字行）。

    规则：连续 3 行以上满足「仅含数字、小数点、空格、百分号」

    Returns:
        (is_detected, line_count)
    """


def detect_header_noise(text: str) -> tuple[bool, list[str]]:
    """
    检测页眉干扰（重复短行）。

    规则：长度 <50 的行出现次数 >3 且内容相同

    Returns:
        (is_detected, repeated_lines)
    """


def calculate_garbled_ratio(text: str) -> float:
    """
    计算乱码比例。

    乱码定义：非以下字符的占比
    - 中文字符 (\\u4e00-\\u9fff)
    - 英文字母 (a-zA-Z)
    - 数字 (0-9)
    - 常用标点 (。，、；：？！""''【】（）《》)
    - 空白字符

    Returns:
        ratio: 0.0-1.0
    """
```

**综合评分函数**:

```python
@dataclass(frozen=True)
class QualityScore:
    """综合质量评分结果"""
    score: int  # 0-100
    needs_review: bool
    penalties: dict[str, int]  # 各项扣分明细


def calculate_quality_score(
    text: str,
    quality_flags: list[str],
    score_detail: ScoreDetail,
) -> QualityScore:
    """
    计算综合质量评分。

    Args:
        text: MD&A 文本
        quality_flags: 现有质量标记
        score_detail: 现有评分细节

    Returns:
        QualityScore: 包含最终评分和 needs_review 标记
    """
    base = 100
    penalties = {}

    # 1. 现有质量标记扣分
    if "FLAG_LENGTH_ABNORMAL" in quality_flags:
        penalties["length_abnormal"] = 10
    if "FLAG_CONTENT_MISMATCH" in quality_flags:
        penalties["content_mismatch"] = 15
    if "FLAG_TAIL_OVERLAP" in quality_flags:
        penalties["tail_overlap"] = 10
    if "FLAG_PAGE_BOUNDARY_MISSING" in quality_flags:
        penalties["page_boundary_missing"] = 5
    if "FLAG_TOC_MISMATCH" in quality_flags:
        penalties["toc_mismatch"] = 10
    if "FLAG_EXTRACT_FAILED" in quality_flags:
        penalties["extract_failed"] = 100  # 直接归零

    # 2. 目录引导线扣分 (基于 score_detail)
    if score_detail.dots_count >= 10:
        penalties["dots_excess"] = 20

    # 3. 新增负向特征检测
    neg_features = detect_negative_features(text)
    if neg_features.table_residue_score > 0:
        penalties["table_residue"] = neg_features.table_residue_score
    if neg_features.header_noise_score > 0:
        penalties["header_noise"] = neg_features.header_noise_score
    if neg_features.garbled_penalty > 0:
        penalties["garbled_text"] = neg_features.garbled_penalty

    # 4. 计算最终分数
    total_penalty = sum(penalties.values())
    final_score = max(0, base - total_penalty)

    return QualityScore(
        score=final_score,
        needs_review=final_score < 60,
        penalties=penalties,
    )
```

### 2. 数据模型变更

**mda_text 表新增字段**:

| 字段 | 类型 | 约束 | 说明 |
|------|------|------|------|
| `quality_score` | INTEGER | DEFAULT NULL | 综合质量评分 (0-100) |
| `needs_review` | BOOLEAN | DEFAULT FALSE | 是否需要人工审核 |

**新增视图**:

```sql
CREATE OR REPLACE VIEW mda_needs_review AS
SELECT
    stock_code,
    year,
    quality_score,
    quality_flags,
    char_count,
    source_path,
    extracted_at
FROM mda_text
WHERE needs_review = true
ORDER BY quality_score ASC, extracted_at DESC;
```

### 3. 数据流更新

```
原流程:
extract_mda_iterative() -> ExtractionResult -> MDAUpsertRecord -> upsert_mda_text()

新流程:
extract_mda_iterative() -> ExtractionResult
                              ↓
                        calculate_quality_score()
                              ↓
                        MDAUpsertRecord (含 quality_score, needs_review)
                              ↓
                        upsert_mda_text()
```

### 4. 接口签名

```python
# data_manager.py

@dataclass(frozen=True)
class MDAUpsertRecord:
    # ... 现有字段 ...

    # 新增字段
    quality_score: Optional[int] = None
    needs_review: bool = False
```

### 5. 测试用例设计

| 场景 | 输入 | 预期 | 优先级 |
|------|------|------|-------|
| 正常高质量文本 | 含关键词、无负向特征 | score ≥ 80, needs_review = false | P0 |
| 表格残留 | 含连续数字行 | 扣 15 分, penalties 含 table_residue | P0 |
| 页眉干扰 | 含重复短行 | 扣 10 分, penalties 含 header_noise | P0 |
| 乱码超标 | 乱码比例 >5% | 扣 20 分, penalties 含 garbled_text | P0 |
| 多特征叠加 | 多个负向特征 | 累计扣分, score = max(0, 100 - total) | P1 |
| 极端案例 | 全是乱码 | score = 0, needs_review = true | P1 |
| 提取失败 | FLAG_EXTRACT_FAILED | score = 0, needs_review = true | P0 |
| 空文本 | text = "" | score = 0, needs_review = true | P0 |

---

## 自我审计 (P3)

### 完备性检查

- [x] 所有负向特征均有检测函数定义
- [x] 评分模型包含所有扣分项
- [x] 数据库字段变更明确
- [x] 数据流更新清晰

### 一致性检查

- [x] 新增字段与现有 quality_flags/quality_detail 不冲突
- [x] QualityScore.penalties 与 quality_detail 可合并存储

### 可落地性检查

- [x] 检测函数均可用正则或简单逻辑实现
- [x] 无需外部依赖（纯 Python 实现）

### 编码规范检查

- [x] 早返回：空文本直接返回 0 分
- [x] 单一职责：每个检测函数只做一件事
- [x] 命名清晰：函数名直接表达功能

---

## 任务拆解 (P4)

### Step 1: 升级评分器 (scorer.py)

- [ ] 新增 `NegativeFeatures` 数据类
- [ ] 实现 `detect_table_residue()` 函数
- [ ] 实现 `detect_header_noise()` 函数
- [ ] 实现 `calculate_garbled_ratio()` 函数
- [ ] 实现 `detect_negative_features()` 函数
- [ ] 新增 `QualityScore` 数据类
- [ ] 实现 `calculate_quality_score()` 函数
→ 验证: 单元测试覆盖所有检测函数

### Step 2: 数据库 Schema 更新 (db.py)

- [ ] `mda_text` 表新增 `quality_score` 和 `needs_review` 字段
- [ ] 新增 `mda_needs_review` 视图
- [ ] 处理现有数据迁移（ALTER TABLE）
→ 验证: DuckDB 查询确认字段存在

### Step 3: 数据管理层更新 (data_manager.py)

- [ ] `MDAUpsertRecord` 新增 `quality_score` 和 `needs_review` 字段
- [ ] `upsert_mda_text()` 更新 INSERT/UPDATE 语句
→ 验证: 插入记录后查询确认字段值正确

### Step 4: 提取流程集成 (mda_extractor.py)

- [ ] 在 `_extract_one_worker()` 中调用 `calculate_quality_score()`
- [ ] 将评分结果写入 `MDAUpsertRecord`
→ 验证: 端到端测试，提取后查询 quality_score

### Step 5: 文档与 Schema 更新

- [ ] 更新 `data/schema.json`
- [ ] 更新 `TODO.md` 标记任务完成
→ 验证: 文档与代码一致

### Step 6: 测试用例编写

- [ ] 编写 `tests/test_scorer.py` 单元测试
- [ ] 编写 `tests/test_quality_integration.py` 集成测试
→ 验证: `pytest tests/test_scorer.py tests/test_quality_integration.py -v` 全部通过
